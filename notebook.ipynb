{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# import dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# suppress cell warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('framingham.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 0\n",
       "age                  0\n",
       "education          105\n",
       "currentSmoker        0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "diaBP                0\n",
       "BMI                 19\n",
       "heartRate            1\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>24.96</td>\n",
       "      <td>80.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>23.14</td>\n",
       "      <td>60.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3656 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male   age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0      1.0  39.0        4.0            0.0         0.0     0.0   \n",
       "1      0.0  46.0        2.0            0.0         0.0     0.0   \n",
       "2      1.0  48.0        1.0            1.0        20.0     0.0   \n",
       "3      0.0  61.0        3.0            1.0        30.0     0.0   \n",
       "4      0.0  46.0        3.0            1.0        23.0     0.0   \n",
       "...    ...   ...        ...            ...         ...     ...   \n",
       "4231   1.0  58.0        3.0            0.0         0.0     0.0   \n",
       "4232   1.0  68.0        1.0            0.0         0.0     0.0   \n",
       "4233   1.0  50.0        1.0            1.0         1.0     0.0   \n",
       "4234   1.0  51.0        3.0            1.0        43.0     0.0   \n",
       "4237   0.0  52.0        2.0            0.0         0.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                 0.0           0.0       0.0    195.0  106.0   70.0  26.97   \n",
       "1                 0.0           0.0       0.0    250.0  121.0   81.0  28.73   \n",
       "2                 0.0           0.0       0.0    245.0  127.5   80.0  25.34   \n",
       "3                 0.0           1.0       0.0    225.0  150.0   95.0  28.58   \n",
       "4                 0.0           0.0       0.0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4231              0.0           1.0       0.0    187.0  141.0   81.0  24.96   \n",
       "4232              0.0           1.0       0.0    176.0  168.0   97.0  23.14   \n",
       "4233              0.0           1.0       0.0    313.0  179.0   92.0  25.97   \n",
       "4234              0.0           0.0       0.0    207.0  126.5   80.0  19.71   \n",
       "4237              0.0           0.0       0.0    269.0  133.5   83.0  21.47   \n",
       "\n",
       "      heartRate  glucose  TenYearCHD  \n",
       "0          80.0     77.0         0.0  \n",
       "1          95.0     76.0         0.0  \n",
       "2          75.0     70.0         0.0  \n",
       "3          65.0    103.0         1.0  \n",
       "4          85.0     85.0         0.0  \n",
       "...         ...      ...         ...  \n",
       "4231       80.0     81.0         0.0  \n",
       "4232       60.0     79.0         1.0  \n",
       "4233       66.0     86.0         1.0  \n",
       "4234       65.0     68.0         0.0  \n",
       "4237       80.0    107.0         0.0  \n",
       "\n",
       "[3656 rows x 16 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data and clean dataset from Nan  infinity or a value too large for dtype('float64')\n",
    "def clean_dataset(data):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "clean_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3656 entries, 0 to 4237\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   male             3656 non-null   int64  \n",
      " 1   age              3656 non-null   int64  \n",
      " 2   education        3656 non-null   float64\n",
      " 3   currentSmoker    3656 non-null   int64  \n",
      " 4   cigsPerDay       3656 non-null   float64\n",
      " 5   BPMeds           3656 non-null   float64\n",
      " 6   prevalentStroke  3656 non-null   int64  \n",
      " 7   prevalentHyp     3656 non-null   int64  \n",
      " 8   diabetes         3656 non-null   int64  \n",
      " 9   totChol          3656 non-null   float64\n",
      " 10  sysBP            3656 non-null   float64\n",
      " 11  diaBP            3656 non-null   float64\n",
      " 12  BMI              3656 non-null   float64\n",
      " 13  heartRate        3656 non-null   float64\n",
      " 14  glucose          3656 non-null   float64\n",
      " 15  TenYearCHD       3656 non-null   int64  \n",
      "dtypes: float64(9), int64(7)\n",
      "memory usage: 485.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "y = df['TenYearCHD']\n",
    "\n",
    "# features\n",
    "X = df.drop('TenYearCHD', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of the imbalance here: there are 557 observations in class 1 and only 3099 in class 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We need the LogisticRegression module from sklearn.linear_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohamed Abubakar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can extract the parameters. The parameters consist of the intercept and the coefficients related to the features. These parameters can be used to predict future target given the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Time\n",
    "Next we will use the predict method to obtain predictions from our test data observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we've made some predictions. Now we can begin to compare those predictions to the ground truth labels of the test dataset, and determine how well the model has actually done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Model Performance using the Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a table that is often used to describe the performance of a classification model, or classifier , on a set of test data for which the true values are known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[607,   5],\n",
       "       [116,   4]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0: No</th>\n",
       "      <th>1: Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0: No</th>\n",
       "      <td>607</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1: Yes</th>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0: No  1: Yes\n",
       "0: No     607       5\n",
       "1: Yes    116       4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['0: No', '1: Yes']\n",
    "\n",
    "pd.DataFrame(data=confusion_matrix(y_test, pred_lr), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Model Performance using the Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the confusion matrix, the classification matrix takes in two arguments: the unseen y_test data as well as our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: No       0.84      0.99      0.91       612\n",
      "      1: Yes       0.44      0.03      0.06       120\n",
      "\n",
      "    accuracy                           0.83       732\n",
      "   macro avg       0.64      0.51      0.49       732\n",
      "weighted avg       0.77      0.83      0.77       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(classification_report(y_test, pred_lr, target_names=['0: No', '1: Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick analysis of the distribution of observations across our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate minority and majority classes\n",
    "no_sample = df[df['TenYearCHD']==0]\n",
    "yes_sample = df[df['TenYearCHD']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get all possible labels\n",
    "labels = df['TenYearCHD'].unique()\n",
    "heights = [len(yes_sample),len(no_sample)]\n",
    "plt.bar(labels,heights,color='grey')\n",
    "plt.xticks(labels,['yes','no'])\n",
    "plt.ylabel(\"# of observations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8476477024070022"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of no_sample in the dataset \n",
    "len(no_sample)/(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our two classes are imbalanced. To put this in perspective as to why this is such an issue, say we had a model that always predicts that a given email is not spam (clearly a really bad model!). Such a model would achieve an accuracy of 85%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual, we start by importing our modules\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 1: Upsampling the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3099\n",
       "0    3099\n",
       "Name: TenYearCHD, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample majority\n",
    "sample_upsampled = resample(yes_sample,\n",
    "                          replace=True, # sample without replacement (no need to duplicate observations)\n",
    "                          n_samples=len(no_sample), # match number in minority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# Combine downsampled majority class with minority class\n",
    "downsampled = pd.concat([sample_upsampled, no_sample])\n",
    "\n",
    "# Check new class counts\n",
    "downsampled['TenYearCHD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "y1 = downsampled['TenYearCHD']\n",
    "\n",
    "# features\n",
    "X1 = downsampled.drop('TenYearCHD', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression model instance\n",
    "lm = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lm = lm.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: no       0.61      0.61      0.61       614\n",
      "      1: yes       0.62      0.62      0.62       626\n",
      "\n",
      "    accuracy                           0.62      1240\n",
      "   macro avg       0.62      0.62      0.62      1240\n",
      "weighted avg       0.62      0.62      0.62      1240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(classification_report(y_test1, pred_lm, target_names=['0: no', '1: yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the scaler module\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Scale data\n",
    "X_scaled = scaler.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_scaled, y1, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a reference model, we'll build a logistic regression classifier using all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_full = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No transformations necessary\n",
    "lm_full.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from full model\n",
    "pred_lm_full = lm_full.predict(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection by Variance Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm instance for var thresh\n",
    "lm_vt = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the var thresh model and choose a threshold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.02)\n",
    "\n",
    "# Transform (i.e.: run selection on) the training data\n",
    "X_train_vt = selector.fit_transform(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4958, 8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a variance threshold of 0.02, we have managed to trim the number of features in the training dataset from 16 down to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model to the transformed data\n",
    "lm_vt.fit(X_train_vt, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll need to remove the same features we did in the thresholding process\n",
    "X_test_vt = selector.transform(X_test2)\n",
    "\n",
    "# Generate predictions from var thresh model\n",
    "pred_lm_vt = lm_vt.predict(X_test_vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: no       0.69      0.66      0.67       614\n",
      "      1: yes       0.68      0.71      0.69       626\n",
      "\n",
      "    accuracy                           0.68      1240\n",
      "   macro avg       0.68      0.68      0.68      1240\n",
      "weighted avg       0.68      0.68      0.68      1240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(classification_report(y_test2, pred_lm_vt, target_names=['0: no', '1: yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by Choosing K-Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm instance for k-best\n",
    "lm_kbest = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the feature selector module\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Set up selector, choosing score function and number of features to retain\n",
    "selector_kbest = feature_selection.SelectKBest(score_func=f_classif, k=5)\n",
    "\n",
    "# Transform (i.e.: run selection on) the training data\n",
    "X_train_kbest = selector_kbest.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4958, 5)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_kbest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model to the transformed data\n",
    "lm_kbest.fit(X_train_kbest, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before generating predictions, we'll need to transform the test data the same way we did the train data\n",
    "X_test_kbest = selector_kbest.transform(X_test)\n",
    "\n",
    "# Generate predictions from var thresh model\n",
    "pred_lm_kbest = lm_kbest.predict(X_test_kbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: no       0.66      0.66      0.66       614\n",
      "      1: yes       0.67      0.67      0.67       626\n",
      "\n",
      "    accuracy                           0.67      1240\n",
      "   macro avg       0.67      0.67      0.67      1240\n",
      "weighted avg       0.67      0.67      0.67      1240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(classification_report(y_test, pred_lm_kbest, target_names=['0: no', '1: yes']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a46c5a272d30d69d5c3259eb2e583983792729bf3d55d9dc6d8feb501fa0ad45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
